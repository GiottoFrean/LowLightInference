{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b686533-ca93-4ea9-aee0-7b3aa487a188",
   "metadata": {},
   "source": [
    "need to compute the density of species by combining information from different agents\n",
    "\n",
    "need to move from low probability areas into high probability areas, minimizing individual movement, \n",
    "but still basically doing a random sample from the density. Shouldn't gather in the center.\n",
    "\n",
    "The current may change, the route things are migrating on might change\n",
    "\n",
    "explore / exploit, value of information\n",
    "\n",
    "How much information can agents send one another?\n",
    "\n",
    "MCMC sampling with minimal movement\n",
    "\n",
    "Measure distance travelled before reaching a particular certainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e292ea-53e1-4c3f-b115-cdda5eca5e06",
   "metadata": {},
   "source": [
    "### The Big Problem\n",
    "\n",
    "In *A - Species inference from movement acoustics* I discussed the potential use of hydrophones to classify deep-sea creatures from the acoustic signature of their movements. Now I'm going to make a slight pivot to talking about how to find animal hotspots in the first place. \n",
    "\n",
    "The ocean, like the surface of the earth, has variation in the number of species. We want to find the places which have lots of things to observe. The problem is that taking observations is a long process. To get a measure of the species density requires going all the way down, capturing sufficient video of what's there, zooming back up, analysing, and then going to somewhere you think might be better. \n",
    "\n",
    "In general this is a scarce data problem. Each datapoint is costly, and we also want to minimise cost. Sample efficiency becomes important. In machine learning there are a few sample efficient algorithms out there. One option is to use a Gaussian Process to fit the data. Gaussian Processes give predictions AND error bars. Given this you can compute the expected improvement you would get by sampling in a new spot. You then choose the point which maximises that property. Below is a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82918aea-253e-4d8e-a80e-f57abf48da72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b079499e-eb1d-44cd-82a8-56dea28a82de",
   "metadata": {},
   "source": [
    "This makes a lot of sense, but this is imagining that each sample has a fixed cost (e.g., drilling for oil). But when it comes to an autonomous agents exploring somewhere this might not be the case. We also care about how far the agent needs to travel between samples. So what do we do then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6466073-20ad-4f10-90ff-80c1b73b8677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
